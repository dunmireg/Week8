{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 9\n",
    "Ron Cordell, Ted Dunmire, Filip Krunic \n",
    "\n",
    "-----\n",
    "\n",
    "### Question 9.1 \n",
    "\n",
    "*Write a basic MRJob implementation of the iterative PageRank algorithm\n",
    "that takes sparse adjacency lists as input (as explored in HW 7).*\n",
    "\n",
    "*Make sure that you implementation utilizes teleportation (1-damping/the number of nodes in the network), and further, distributes the mass of dangling nodes with each iteration\n",
    "so that the output of each iteration is correctly normalized (sums to 1).*\n",
    "\n",
    "#### Solution\n",
    "\n",
    "In spirit of the previous homeworks, we implement a `driver` and subroutine modules to do various parts of the calculation. In particular, the driver will manage the overall process and the PageRank script will calculate the PageRank values for the dataset to be used. \n",
    "\n",
    "##### Driver \n",
    "\n",
    "Below is the driver for the PageRank process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile driver.py\n",
    "from __future__ import division\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.emr import EMRJobRunner\n",
    "\n",
    "from init_pr import pageRank\n",
    "from number_of_nodes import numNodes\n",
    "\n",
    "import cPickle as pickle\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import argparse \n",
    "\n",
    "# Storage files \n",
    "s3Bucket = 's3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt'\n",
    "dataFile = 'PageRank-test.txt'\n",
    "emrID = 'j-8176IR8VX5LF'\n",
    "\n",
    "\n",
    "def getName(obj, namespace):\n",
    "\treturn [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "def extractValues(job, runner):\n",
    "\toutput = defaultdict(int)\n",
    "\tfor line in runner.stream_output(): \n",
    "\t\tkey, value = job.parse_output_line(line)\n",
    "\t\toutput[key] = value\n",
    "\n",
    "\treturn output \n",
    "\n",
    "\n",
    "def dumpToFile(variable, filename):\n",
    "\twith open(filename, 'w') as f: \n",
    "\t\tpickle.dump(variable, f)\n",
    "\n",
    "\n",
    "def runJob(method, args, emr=False):\n",
    "\tjob = method(args=args)\n",
    "\n",
    "\tmethodName = getName(method, globals())[0]\n",
    "\tprint '\\n\\t' + 'Running ' + methodName + '...'\n",
    "\n",
    "\twith job.make_runner() as runner: \n",
    "\n",
    "\t\trunner.run()\n",
    "\t\tresult = extractValues(job, runner)\n",
    "\n",
    "\t\tprint '\\t' + 'Complete: ' + methodName\t\n",
    "\n",
    "\t\treturn result \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\t# Arguments \n",
    "\tparser = argparse.ArgumentParser(description='Driver for PageRank in MRJob.')\n",
    "\n",
    "\tparser.add_argument('--emr', default=None, action='store_true',\n",
    "\t\t\t\t\t   help='Flag for using the EMR (and S3 bucket).')\n",
    "\n",
    "\tparser.add_argument('--iterations', default=10, \n",
    "\t\t\t\t\t\t\thelp='Number of iterations to use for PageRank.')\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\n",
    "\t# Pass \n",
    "\tif args.emr: \n",
    "\t\t# argInput = [s3Bucket, '-r', 'emr', '--no-strict-protocols', \\\n",
    "\t\t# \t\t'--emr-job-flow-id', emrID]\n",
    "\n",
    "\t\targInput = [s3Bucket, '-r', 'emr']\n",
    "\n",
    "\telse: \n",
    "\t\targInput = [dataFile]\n",
    "\n",
    "\n",
    "\t# Get node counts \n",
    "\ttotalNodeTuple = runJob(numNodes, args=argInput)\n",
    "\ttotalNodes = totalNodeTuple.values()[0]\n",
    "\t\n",
    "\tprint 'NUMNODES: %s' % (totalNodes)\n",
    "\n",
    "\t# Execute \n",
    "\ttopNodes = runJob(pageRank, args=argInput + ['--numberOfNodes=%s' % (totalNodes)] + \\\n",
    "\t\t\t\t\t['--iterations=%s' % (args.iterations)])\n",
    "\n",
    "\tnodeTuples = [(key, round(value, 5)) for (key, value) in topNodes.iteritems()]\n",
    "\tsortedNodes = sorted(nodeTuples, key=itemgetter(1), reverse=True)\n",
    "\n",
    "\t# Emit \n",
    "\tfor k, v in sortedNodes:\n",
    "\t\tprint 'ID: %s \\t PR: %s' % (k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Nodes \n",
    "\n",
    "Below is the class to compute the number of nodes. This is important for PageRank as it could affect the values at the end if the number of nodes is not instantiated accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting number_of_nodes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile number_of_nodes.py\n",
    "from __future__ import division\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    " \n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "class numNodes(MRJob):\n",
    "\n",
    "\t\"\"\" Counts the number of nodes. \"\"\"\n",
    "\n",
    "\tdef mapper(self, _, line):\n",
    "\n",
    "\t\t\"\"\" Emit raw nodes. \"\"\"\n",
    "\n",
    "\t\t# Parse \n",
    "\t\tline = line.split('\\t')\n",
    "\t\tnode = line[0]\n",
    "\t\tadjacencyList = eval(line[1])\n",
    "\n",
    "\t\t# Track \n",
    "\t\tfor neighbor in adjacencyList.keys(): \n",
    "\n",
    "\t\t   # Emit raw nodes\n",
    "\t\t   yield neighbor, None\n",
    "\n",
    "\n",
    "\t\t# Pass values\n",
    "\t\tyield node, None\n",
    "\n",
    "\n",
    "\tdef reducer_duplicates(self, node, _):\n",
    "\n",
    "\t\t\"\"\" Emit count for each unique node. \"\"\"\n",
    "\n",
    "\t\tyield None, 1 \n",
    "\n",
    "\n",
    "\tdef reducer_aggregate(self, _, totalNodes):\n",
    "\n",
    "\t\t\"\"\" Aggregate counts. \"\"\"\n",
    "\n",
    "\t\tyield None, sum(totalNodes)\n",
    "\n",
    "\n",
    "\tdef steps(self):\n",
    "\n",
    "\t\treturn [MRStep(mapper=self.mapper, \n",
    "\t\t\t\t\t\treducer=self.reducer_duplicates), \n",
    "\n",
    "\t\t\t\tMRStep(reducer=self.reducer_aggregate)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tnumNodes().run()\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### PageRank \n",
    "\n",
    "Below is the implementation for PageRank. It defaults to a set number of nodes based on either an estimate for EMR based jobs, or a `11` for the test dataset in question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting init_pr.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile init_pr.py\n",
    "from __future__ import division\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    " \n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "class pageRank(MRJob):\n",
    " \n",
    "     \"\"\" This class implements the page-rank calculation. \"\"\"\n",
    "\n",
    "\n",
    "     def configure_options(self):\n",
    "\n",
    "          \"\"\" Load options for the class. \"\"\"\n",
    "\n",
    "          super(pageRank, self).configure_options()\n",
    "\n",
    "          self.add_passthrough_option('--alpha',\n",
    "               default=0.85, type=float, help='alpha: Dampening factor for teleportation in PageRank')\n",
    "\n",
    "          self.add_passthrough_option('--iterations',\n",
    "               default=10, type=int, help='iterations: number of iterations for PageRank')\n",
    "\n",
    "          self.add_passthrough_option('--manualPower', \n",
    "               default=7, type=int, help='manualPower: order of magnitude for number of nodes.')\n",
    "\n",
    "          self.add_passthrough_option('--numberOfNodes', \n",
    "               default=None, type=int, help='numberOfNodes: The number of nodes in your graph. Used for teleporation.')\n",
    "\n",
    "\n",
    "     def load_options(self, args):\n",
    "\n",
    "          \"\"\" Initializes the arguments for each class. \"\"\"\n",
    "\n",
    "          super(pageRank, self).load_options(args)\n",
    "\n",
    "          self.alpha = self.options.alpha\n",
    "          self.iterations = self.options.iterations\n",
    "\n",
    "          # Check number of nodes \n",
    "          if self.options.numberOfNodes:\n",
    "               self.numberOfNodes = self.options.numberOfNodes\n",
    "\n",
    "          else:\n",
    "               self.numberOfNodes = pow(10, self.options.manualPower)\n",
    "\n",
    "\n",
    "     def mapper_init_pr(self, _, line):\n",
    "\n",
    "          \"\"\" This initializes the PageRank algorithm by assembling the node list \n",
    "          for the initial PageRank values. \"\"\"\n",
    "\n",
    "          # Parse \n",
    "          line = line.split('\\t')\n",
    "          node = line[0]\n",
    "          adjacencyList = eval(line[1])\n",
    "\n",
    "          # Track \n",
    "          for neighbor in adjacencyList.keys(): \n",
    "\n",
    "               # Emit raw nodes\n",
    "               yield neighbor, None\n",
    "\n",
    "\n",
    "          # Pass values\n",
    "          yield node, adjacencyList\n",
    "\n",
    "\n",
    "     def reducer_init_pr(self, node, initTuple):\n",
    "\n",
    "          \"\"\" This attaches initial PageRanks for the algorithm. \"\"\"\n",
    "\n",
    "          adjacencyList = dict()\n",
    "\n",
    "          # Re-discover \n",
    "          for element in initTuple:\n",
    "               if isinstance(element, dict):\n",
    "                    adjacencyList = element \n",
    "\n",
    "          # Initialize PR\n",
    "          PageRank = float(1) / float(self.numberOfNodes)\n",
    "\n",
    "          # Emit\n",
    "          yield node, (adjacencyList, PageRank)\n",
    "\n",
    "\n",
    "     def mapper_iterate_pr(self, node, nodeTuple):\n",
    "\n",
    "          \"\"\" This projects all of the PageRank weights for each node's neighbor. \"\"\"\n",
    "\n",
    "          adjacencyList, PageRank = nodeTuple\n",
    "\n",
    "          if not adjacencyList:\n",
    "               pass\n",
    "\n",
    "          else: \n",
    "\n",
    "               # Emit PR \n",
    "               for neighbor in adjacencyList.keys(): \n",
    "                    yield neighbor, PageRank / len(adjacencyList)\n",
    "\n",
    "          # Emit structure \n",
    "          yield node, adjacencyList\n",
    "\n",
    "\n",
    "     def reducer_iterate_pr(self, node, PRNodeObject):\n",
    "\n",
    "          \"\"\" This reconstructs the graph structure form the updated PageRanks. \"\"\"\n",
    "\n",
    "          updatedPR = 0\n",
    "\n",
    "          # Combine PR \n",
    "          for value in PRNodeObject:\n",
    "               if isinstance(value, dict):\n",
    "                    adjacencyList = value \n",
    "\n",
    "               else: \n",
    "                    updatedPR += value \n",
    "\n",
    "          # Damping factor \n",
    "          updatedPR = ((1 - self.alpha) / self.numberOfNodes) + self.alpha * updatedPR\n",
    "\n",
    "          # Emit \n",
    "          yield node, (adjacencyList, updatedPR)\n",
    "\n",
    "\n",
    "     def mapper_sort(self, node, nodeTuple):\n",
    "\n",
    "          \"\"\" Emits the page rank for each node. \"\"\"\n",
    "\n",
    "          adjacencyList, PageRank = nodeTuple\n",
    "\n",
    "          yield None, (node, PageRank)\n",
    "\n",
    "\n",
    "     def reducer_sort(self, _, PageRankPair):\n",
    "\n",
    "          \"\"\" Keeps the top 100 PageRank values. \"\"\"\n",
    "\n",
    "          sortedList = []\n",
    "\n",
    "          # Iterate and remove \n",
    "          for node, score in PageRankPair:\n",
    "\n",
    "               sortedList.append((node, score))\n",
    "               sortedList = sorted(sortedList, key=itemgetter(1), reverse=True)\n",
    "\n",
    "               if len(sortedList) > 100: \n",
    "                    sortedList.pop()\n",
    "\n",
    "          # Emit \n",
    "          for node, score in sortedList: \n",
    "               yield node, score\n",
    "\n",
    "\n",
    "     def steps(self):\n",
    "\n",
    "          \"\"\" Determines the steps for the job. Has two phases- initiate PR and iterate. \"\"\"\n",
    "\n",
    "          initializeStep = [\n",
    "\n",
    "               MRStep(mapper=self.mapper_init_pr, \n",
    "                         reducer=self.reducer_init_pr)\n",
    "\n",
    "          ]\n",
    "\n",
    "          iterateStep = [\n",
    "\n",
    "               MRStep(mapper=self.mapper_iterate_pr, \n",
    "                         reducer=self.reducer_iterate_pr)         \n",
    "\n",
    "          ]\n",
    "\n",
    "          sortStep = [\n",
    "\n",
    "               MRStep(mapper=self.mapper_sort, \n",
    "                         reducer=self.reducer_sort)\n",
    "\n",
    "          ]\n",
    "\n",
    "          return initializeStep + iterateStep * self.iterations + sortStep\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "               pageRank().run()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute \n",
    "\n",
    "We run the code now for the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tRunning numNodes...\n",
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "\tComplete: numNodes\n",
      "NUMNODES: 11\n",
      "\n",
      "\tRunning pageRank...\n",
      "\tComplete: pageRank\n",
      "ID: C \t PR: 0.30973\n",
      "ID: B \t PR: 0.30362\n",
      "ID: E \t PR: 0.06821\n",
      "ID: D \t PR: 0.03298\n",
      "ID: F \t PR: 0.03298\n",
      "ID: A \t PR: 0.02765\n",
      "ID: G \t PR: 0.01364\n",
      "ID: I \t PR: 0.01364\n",
      "ID: H \t PR: 0.01364\n",
      "ID: K \t PR: 0.01364\n",
      "ID: J \t PR: 0.01364\n"
     ]
    }
   ],
   "source": [
    "!python driver.py --iterations=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 \n",
    "\n",
    "*Run your PageRank implementation on the Wikipedia dataset for 10 iterations,\n",
    "and display the top 100 ranked nodes (with alpha = 0.85).*\n",
    "\n",
    "*Run your PageRank implementation on the Wikipedia dataset for 50 iterations,\n",
    "and display the top 100 ranked nodes (with teleportation factor of 0.15). \n",
    "Have the top 100 ranked pages changed? Comment on your findings. Plot the pagerank values for the top 100 pages resulting from the 50 iterations run. Then plot the pagerank values for the same 100 pages that resulted from the 10 iterations run.*\n",
    "\n",
    "#### Solution: \n",
    "\n",
    "Below we run our PageRank for 5 and 10 iterations, respectively. \n",
    "\n",
    "##### 5 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\tRunning numNodes...\r\n",
      "No handlers could be found for logger \"mrjob.conf\"\r\n"
     ]
    }
   ],
   "source": [
    "!python driver.py --emr --iterations=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True registered\n",
      "\n",
      "\tRunning numNodes...\n",
      "No handlers could be found for logger \"mrjob.conf\"\n",
      "\tComplete: numNodes\n",
      "\n",
      "\tRunning pageRank...\n",
      "\tComplete: pageRank\n",
      "ID: 3191491 \t PR: 0.0001\n",
      "ID: 4624519 \t PR: 4e-05\n",
      "ID: 6113490 \t PR: 0.00013\n",
      "ID: 2437837 \t PR: 0.00013\n",
      "ID: 13853369 \t PR: 4e-05\n",
      "ID: 3591832 \t PR: 3e-05\n",
      "ID: 9997298 \t PR: 5e-05\n",
      "ID: 6076759 \t PR: 0.00012\n",
      "ID: 7467127 \t PR: 3e-05\n",
      "ID: 6416278 \t PR: 9e-05\n",
      "ID: 5490435 \t PR: 5e-05\n",
      "ID: 12038331 \t PR: 4e-05\n",
      "ID: 1637982 \t PR: 6e-05\n",
      "ID: 9924814 \t PR: 3e-05\n",
      "ID: 994890 \t PR: 5e-05\n",
      "ID: 13425865 \t PR: 0.00013\n",
      "ID: 6237129 \t PR: 9e-05\n",
      "ID: 9276255 \t PR: 9e-05\n",
      "ID: 1523975 \t PR: 4e-05\n",
      "ID: 9394907 \t PR: 5e-05\n",
      "ID: 12785678 \t PR: 3e-05\n",
      "ID: 1813634 \t PR: 4e-05\n",
      "ID: 2778099 \t PR: 4e-05\n",
      "ID: 3603527 \t PR: 7e-05\n",
      "ID: 5051368 \t PR: 0.00016\n",
      "ID: 6172167 \t PR: 5e-05\n",
      "ID: 3069099 \t PR: 7e-05\n",
      "ID: 15164193 \t PR: 0.0001\n",
      "ID: 4568647 \t PR: 3e-05\n",
      "ID: 9386580 \t PR: 7e-05\n",
      "ID: 7990491 \t PR: 8e-05\n",
      "ID: 11582765 \t PR: 5e-05\n",
      "ID: 11148415 \t PR: 4e-05\n",
      "ID: 10399499 \t PR: 4e-05\n",
      "ID: 7835160 \t PR: 9e-05\n",
      "ID: 14725161 \t PR: 5e-05\n",
      "ID: 8697871 \t PR: 5e-05\n",
      "ID: 5908108 \t PR: 3e-05\n",
      "ID: 9742161 \t PR: 3e-05\n",
      "ID: 10345830 \t PR: 4e-05\n",
      "ID: 1384888 \t PR: 0.00013\n",
      "ID: 10527224 \t PR: 5e-05\n",
      "ID: 1516699 \t PR: 9e-05\n",
      "ID: 4198751 \t PR: 8e-05\n",
      "ID: 6171937 \t PR: 5e-05\n",
      "ID: 2797855 \t PR: 8e-05\n",
      "ID: 2826544 \t PR: 4e-05\n",
      "ID: 14503460 \t PR: 7e-05\n",
      "ID: 14963657 \t PR: 4e-05\n",
      "ID: 9562547 \t PR: 5e-05\n",
      "ID: 4978429 \t PR: 4e-05\n",
      "ID: 12447593 \t PR: 4e-05\n",
      "ID: 4196067 \t PR: 0.00012\n",
      "ID: 5274313 \t PR: 3e-05\n",
      "ID: 3191268 \t PR: 6e-05\n",
      "ID: 14112408 \t PR: 6e-05\n",
      "ID: 13455888 \t PR: 0.00042\n",
      "ID: 14727077 \t PR: 3e-05\n",
      "ID: 14565507 \t PR: 4e-05\n",
      "ID: 9355455 \t PR: 6e-05\n",
      "ID: 7902219 \t PR: 0.00013\n",
      "ID: 13328060 \t PR: 4e-05\n",
      "ID: 10469541 \t PR: 9e-05\n",
      "ID: 9391762 \t PR: 5e-05\n",
      "ID: 14881689 \t PR: 7e-05\n",
      "ID: 4695850 \t PR: 0.00018\n",
      "ID: 14981725 \t PR: 4e-05\n",
      "ID: 13725487 \t PR: 9e-05\n",
      "ID: 1575979 \t PR: 4e-05\n",
      "ID: 10566120 \t PR: 6e-05\n",
      "ID: 11147327 \t PR: 6e-05\n",
      "ID: 14709489 \t PR: 3e-05\n",
      "ID: 3328327 \t PR: 3e-05\n",
      "ID: 11245362 \t PR: 6e-05\n",
      "ID: 10390714 \t PR: 0.0001\n",
      "ID: 1175360 \t PR: 4e-05\n",
      "ID: 7576704 \t PR: 9e-05\n",
      "ID: 3973000 \t PR: 3e-05\n",
      "ID: 8019937 \t PR: 4e-05\n",
      "ID: 13432150 \t PR: 4e-05\n",
      "ID: 11253108 \t PR: 7e-05\n",
      "ID: 2578813 \t PR: 4e-05\n",
      "ID: 6172466 \t PR: 0.00011\n",
      "ID: 14112583 \t PR: 0.00011\n",
      "ID: 2614578 \t PR: 5e-05\n",
      "ID: 4344962 \t PR: 4e-05\n",
      "ID: 1332806 \t PR: 4e-05\n",
      "ID: 12430985 \t PR: 6e-05\n",
      "ID: 10246542 \t PR: 3e-05\n",
      "ID: 2155467 \t PR: 7e-05\n",
      "ID: 981395 \t PR: 5e-05\n",
      "ID: 12836211 \t PR: 8e-05\n",
      "ID: 2396749 \t PR: 6e-05\n",
      "ID: 12067030 \t PR: 5e-05\n",
      "ID: 12074312 \t PR: 7e-05\n",
      "ID: 5154210 \t PR: 8e-05\n",
      "ID: 1184351 \t PR: 0.00019\n",
      "ID: 13280859 \t PR: 5e-05\n",
      "ID: 1441065 \t PR: 7e-05\n",
      "ID: 2614581 \t PR: 6e-05\n"
     ]
    }
   ],
   "source": [
    "!python driver.py --emr --iterations=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
